{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4fa6f3f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Pipeline\n",
    "\n",
    "Thus far, we've applied the preprocessing, epoching, and averaging steps to a single participant only.\n",
    "However, we typically study a larger group of participants.\n",
    "This is because (a) data from a single participant is typically quite noisy, and (b) we want to generalize our findings to the population from which our participants were drawn.\n",
    "\n",
    "Therefore, we need to repeat the analysis for all participants by creating an **analysis pipeline** that takes each participant's raw data as an input and performs the same set of processing steps on them.\n",
    "\n",
    "We will first do this manually (using a loop) and then with a pre-packaged automatic pipeline function.\n",
    "\n",
    "```{admonition} Goals\n",
    ":class: note\n",
    "\n",
    "* Repeating the processing steps for all participants\n",
    "* Using a fully automated pipeline\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0dd6ce",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Load Python packages\n",
    "\n",
    "The functions for our custom pipeline are again provided by the [MNE-Python](https://mne.tools/stable/index.html) package {cite:p}`gramfort2013` and [pandas](https://pandas.pydata.org).\n",
    "We will also use the [hu-neuro-pipeline](https://hu-neuro-pipeline.readthedocs.io] package for the fully automated pipeline, plus two new packages ([matplotlib](https://matplotlib.org) and [seaborn](https://seaborn.pydata.org)) for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install mne hu-neuro-pipeline pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mne import Epochs, combine_evoked, merge_events, set_bipolar_reference\n",
    "from mne.io import read_raw\n",
    "from mne.preprocessing import ICA\n",
    "from mne.viz import plot_compare_evokeds\n",
    "from pipeline import group_pipeline\n",
    "from pipeline.datasets import get_erpcore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784eb02e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Custom pipeline\n",
    "\n",
    "We'll start by creating a custom pipeline that repeats the preprocessing, epoching, and averaging steps for all participants.\n",
    "This is as easy as taking all the code from the previous chapters and, instead of reading only a single raw EEG file, putting it inside a `for` loop that iterates over all raw EEG files.\n",
    "\n",
    "Let's first download some more datasets (for the sake of time, we're only using 10 participants instead of all 40):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641d893",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "files_dict = get_erpcore('N170', participants=10, path='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575bc8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f71d1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Then we'll run a `for` loop with all the processing steps inside it.\n",
    "Before the loop, we create empty lists where we will store the processed outputs (in this case, the evokeds) for all participants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd2756",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "evokeds_face = []\n",
    "evokeds_car = []\n",
    "evokeds_diff = []\n",
    "\n",
    "for raw_file, log_file in zip(files_dict['raw_files'],\n",
    "                              files_dict['log_files']):\n",
    "\n",
    "    # Preprocessing\n",
    "    raw = read_raw(raw_file, preload=True)\n",
    "    raw = set_bipolar_reference(raw, anode='FP1', cathode='VEOG_lower',\n",
    "                                ch_name='VEOG', drop_refs=False)\n",
    "    raw = set_bipolar_reference(raw, anode='HEOG_right', cathode='HEOG_left',\n",
    "                                ch_name='HEOG', drop_refs=False)\n",
    "    raw = raw.set_channel_types({'VEOG': 'eog', 'HEOG': 'eog'})\n",
    "    raw = raw.drop_channels(['VEOG_lower', 'HEOG_right', 'HEOG_left'])\n",
    "    raw = raw.set_montage('biosemi64', match_case=False)\n",
    "    raw = raw.filter(l_freq=0.1, h_freq=30.0)\n",
    "    raw_copy = raw.copy().filter(l_freq=1.0, h_freq=None, verbose=False)\n",
    "    ica = ICA(n_components=15)\n",
    "    ica = ica.fit(raw_copy)\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(raw, ch_name=['VEOG', 'HEOG'],\n",
    "                                                verbose=False)\n",
    "    ica.exclude = eog_indices\n",
    "    raw = ica.apply(raw)\n",
    "    raw = raw.set_eeg_reference('average')\n",
    "\n",
    "    # Epoching\n",
    "    log = pd.read_csv(log_file, sep='\\t')\n",
    "    events = log[['sample', 'duration', 'value']].values.astype(int)\n",
    "    events = merge_events(events, ids=range(1, 41), new_id=1)\n",
    "    events = merge_events(events, ids=range(41, 81), new_id=2)\n",
    "    event_id = {'face': 1, 'car': 2}\n",
    "    epochs = Epochs(raw, events, event_id, tmin=-0.2, tmax=0.8,\n",
    "                    baseline=(-0.2, 0.0), preload=True)\n",
    "    epochs = epochs.drop_bad({'eeg': 200e-6})\n",
    "\n",
    "    # Averaging\n",
    "    evoked_face = epochs['face'].average()\n",
    "    evokeds_face.append(evoked_face)\n",
    "    evoked_car = epochs['car'].average()\n",
    "    evokeds_car.append(evoked_car)\n",
    "    evoked_list = [evoked_face, evoked_car]\n",
    "    evoked_diff = combine_evoked(evoked_list, weights=[1, -1])\n",
    "    evokeds_diff.append(evoked_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c690946d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We have collected the averaged ERP (evoked) for both conditions (face and car) from all participants.\n",
    "Averaging one more time, this time not across trials but across participants, gives us the **grand average**.\n",
    "Let's do this separately for both condition and display the grand averages as a time course plot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25da113",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_evoked_face = combine_evoked(evokeds_face, weights='equal')\n",
    "grand_evoked_face.comment = 'face'\n",
    "\n",
    "grand_evoked_car = combine_evoked(evokeds_car, weights='equal')\n",
    "grand_evoked_car.comment = 'car'\n",
    "\n",
    "grand_evoked_list = [grand_evoked_face, grand_evoked_car]\n",
    "_ = plot_compare_evokeds(grand_evoked_list, picks='PO8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12b77fe",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We see that the first negative peak in the ERP (N1/N170 component) is earlier and (and maybe also larger) for faces than for cars.\n",
    "\n",
    "This becomes even more apparent when grand-averaging and plotting the difference waves:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_evoked_diff = combine_evoked(evokeds_diff, weights='equal')\n",
    "grand_evoked_diff.comment = 'face - car'\n",
    "_ = grand_evoked_diff.plot(picks='PO8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c3dc9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The corresponding butterfly and scalp topography plot looks like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = grand_evoked_diff.plot_joint(times=[0.0, 0.15, 0.17])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787158e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Neuro Lab pipeline\n",
    "\n",
    "At the [Abdel Rahman Lab for Neurocognitive Psychology](https://abdelrahmanlab.com) at HU Berlin (the \"Neuro Lab,\" for short), we've developed a Python package that provides a fully automated EEG processing pipeline.\n",
    "The pipeline was originally developed and published in the MATLAB language by {cite:t}`fromer2018`.\n",
    "The more recent Python version is available at [https://hu-neuro-pipeline.readthedocs.io](https://hu-neuro-pipeline.readthedocs.io).\n",
    "\n",
    "The pipeline is fully automated in the sense that it takes raw EEG data from multiple participants as an input and performs a number of standardized processing step at the participant and group level with minimal user input.\n",
    "The typical steps are visualized in this flowchart:\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"https://hu-neuro-pipeline.readthedocs.io/en/stable/_images/flowchart.svg\" alt=\"Flowchart of the processing steps in the `hu-neuro-pipeline package`\" width=400>\n",
    "\n",
    "Processing steps in the `hu-neuro-pipeline` package.\n",
    "Source: [Docs](https://hu-neuro-pipeline.readthedocs.io/en/stable/processing_overview.html).\n",
    ":::\n",
    "\n",
    "The pipeline package only has one main function, called `group_pipeline()`.\n",
    "Let's use it to process the same example data as before:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f6750b",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "trials, evokeds, config = group_pipeline(raw_files=files_dict['raw_files'],\n",
    "                                         log_files=files_dict['log_files'],\n",
    "                                         output_dir='output',\n",
    "                                         montage='biosemi64',\n",
    "                                         ica_method='fastica',\n",
    "                                         ica_n_components=15,\n",
    "                                         triggers=range(1, 81),\n",
    "                                         skip_log_conditions={'value': range(81, 203)},\n",
    "                                         components={'name': 'N170',\n",
    "                                                     'tmin': 0.15,\n",
    "                                                     'tmax': 0.2,\n",
    "                                                     'roi': ['PO8']},\n",
    "                                         average_by={'face': 'value <= 40',\n",
    "                                                     'car': 'value > 40'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a4589",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "In this example we've specified:\n",
    "\n",
    "* The input and output file paths (`raw_files`, `log_files`, `output_dir`)\n",
    "* Some preprocessing options (`montage`, `ica_method`, `ica_n_components`; note that the pipeline also applies a 0.1--40 Hz band-pass filter by default)\n",
    "* The event codes of interest for epoching (`triggers`; note that the pipeline also applies a default peak-to-peak rejection at 200 µV)\n",
    "* Some event codes to skip (`skip_log_conditions`; anything other than faces and houses)\n",
    "* The definition of our ERP component(s) of interest (`components`; here only the N170)\n",
    "* Rules to create by-participant condition averages/evokeds (`average_by`; here for faces and cars)\n",
    "\n",
    "A (long) list of these and all other input options is available on the [pipeline documentation website](https://hu-neuro-pipeline.readthedocs.io/en/stable/usage_inputs.html).\n",
    "\n",
    "The pipeline returns three objects (which also get written as text files into the `output_dir`):\n",
    "\n",
    "* `trials`: A data frame with the **single trial data** for all participants, also containing the single trial ERP amplitudes (averaged across the time window and channels of interest)\n",
    "* `evokeds`: A data frame with the **averaged (evoked) ERP amplitudes** for all time points, channels, and participants\n",
    "* `config`: A dictionary with the **pipeline configuration**\n",
    "\n",
    "Let's look of each of these in turn:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539697c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Single trial data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a2ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f827eca",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We could (and will!) use this for statistically analyzing the ERP component(s) of interest.\n",
    "Specifically, we can fit a mixed-effects model that tests if the single trial N170 amplitudes differs as a function of the condition of the trial (face vs. car).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92478f1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Evokeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a683d3c",
   "metadata": {},
   "source": [
    "The evokeds can be used for plotting the ERP time courses for both conditions.\n",
    "For this, we will use the [seaborn package](https://seaborn.pydata.org), which is great for visualizing tabular data (similar to the [ggplot2 package](https://ggplot2.tidyverse.org) in R)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1fdac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lineplot(evokeds, x='time', y='PO8', hue='label',\n",
    "                 estimator='mean', errorbar='se')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e40a5fc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We can make the plot yet a bit prettier by adding custom x-axis limits, vertical and horizontal lines at zero, and more informative axis labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e49604",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lineplot(evokeds, x='time', y='PO8', hue='label',\n",
    "                 estimator='mean', errorbar='se')\n",
    "_ = plt.margins(x=0.0, y=0.1)\n",
    "_ = plt.xlim(-0.2, 0.8)\n",
    "_ = plt.axvline(0.0, color='black', linestyle='--')\n",
    "_ = plt.axhline(0.0, color='black', linestyle='--')\n",
    "_ = plt.xlabel('Time (s)')\n",
    "_ = plt.ylabel('PO8 amplitude (µV)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae4b32b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Pipeline configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74adda5f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Finally, the `config` output is a dictionary with information about the pipeline run.\n",
    "It contains all the user-specified and default input arguments plus some new information that the pipeline has computed along the way (e.g., `'auto_rejected_epochs'`, the rejected epochs for each participant):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c21f8a",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9895456",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Run the EEG analysis pipeline (using a custom `for` loop or the `group_pipeline()` function) for 10 participants from a different ERP CORE experiment (valid experiment names are `'N170'`, `'MMN'`, `'N2pc'`, `'N400'`, `'P3'`, or `'ERN'`).\n",
    "   Create evokeds for the two conditions of interest and visualize their time course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7132f46",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea80bd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Further reading\n",
    "\n",
    "* Paper *Group-level EEG-processing pipeline for flexible single trial-based analyses including linear mixed models* {cite:p}`fromer2018`\n",
    "* hu-neuro-pipeline package [documentation](https://hu-neuro-pipeline.readthedocs.io)\n",
    "* [Slides](https://github.com/alexenge/hu-neuro-pipeline-workshop) on the hu-neuro-pipeline package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7582f9",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
