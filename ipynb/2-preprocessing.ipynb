{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b71e65",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "**Preprocessing** is the first step in EEG data analysis.\n",
    "It usually involves a series of steps aimed at removing non-brain-related noise and artifacts from the data.\n",
    "Unlike the following steps (e.g., epoching and averaging), it leaves the data in a continuous format (EEG channels × timepoints).\n",
    "\n",
    "```{admonition} Learning goals\n",
    ":class: note\n",
    "\n",
    "* Loading raw EEG data\n",
    "* Plotting the raw data\n",
    "* Filtering the data to remove low and high frequency noise\n",
    "* Correcting eye artifacts using independent component analysis (ICA)\n",
    "* Re-referencing the data to an average reference\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72e431",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Load Python modules\n",
    "\n",
    "We will use the following Python modules:\n",
    "* [MNE-Python](https://mne.tools/stable/index.html) for EEG data analysis {cite:p}`gramfort2013`\n",
    "* [hu-neuro-pipeline](https://github.com/alexenge/hu-neuro-pipeline) for downloading example data\n",
    "\n",
    "Note that on Google Colab, you will need to install these modules first.\n",
    "You can uncomment and run the following cell to do so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install mne hu-neuro-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ab381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import set_bipolar_reference\n",
    "from mne.io import read_raw\n",
    "from mne.preprocessing import ICA\n",
    "from mne.viz import set_browser_backend\n",
    "from pipeline.datasets import get_erpcore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3977a770",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Download example data\n",
    "\n",
    "We'll use data from the ERP CORE dataset {cite:p}`kappenman2021`.\n",
    "This dataset contains EEG data from 40 participants and 6 different experiments.\n",
    "Each experiment was designed to elicit one or two commonly studied ERP components.\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S1053811920309502-gr1.jpg\" width=\"500\">\n",
    "\n",
    "The six different ERP CORE experiments.\n",
    "Source: {cite:t}`kappenman2021`\n",
    ":::\n",
    "\n",
    "In this example, we'll use the data from the fourth participant in the face perception (N170) experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c62fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict = get_erpcore('N170', participants='sub-004', path='data')\n",
    "files_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a23fa",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Load raw data\n",
    "\n",
    "We read the actual EEG data files (`eeg.set`/`eeg.fdt`) into MNE-Python.\n",
    "The result is a `Raw` object, which contains the continuous EEG data and some metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file = files_dict['raw_files'][0]\n",
    "raw = read_raw(raw_file, preload=True)\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67930d4f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We can access the actual data array (a Numpy array) using the `get_data()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c9a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7635e0e4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Let's check the size (number of dimensions and their length) of this array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abcd516",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.get_data().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dcd135",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We see that it has two dimensions (EEG channels × timepoints).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c132a1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Plot raw data\n",
    "\n",
    "We can plot the raw data using the `plot()` method.\n",
    "We specify which time segment of the data to plot using the `start` and `duration` arguments.\n",
    "Here we plot 5 seconds of data, starting at 60 seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11bce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = raw.plot(start=60.0, duration=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e250603",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Add channel information\n",
    "\n",
    "Right now, MNE thinks that all channels are EEG channels.\n",
    "However, we know that some of them are actually EOG channels that record eye movements and blinks.\n",
    "We'll use these to create new \"virtual\" EOG channels that pick up strong eye signals (vertical EOG [VEOG] = difference between above and below the eyes; horizontal EOG [HEOG] = difference between left and right side of the eyes).\n",
    "We explicitly set their channel type to `'eog'` and drop the original channels, so that we are left with 30 EEG channels and 2 EOG channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = set_bipolar_reference(raw, anode='FP1', cathode='VEOG_lower',\n",
    "                            ch_name='VEOG', drop_refs=False)\n",
    "raw = set_bipolar_reference(raw, anode='HEOG_right', cathode='HEOG_left',\n",
    "                            ch_name='HEOG', drop_refs=False)\n",
    "raw = raw.set_channel_types({'VEOG': 'eog', 'HEOG': 'eog'})\n",
    "raw = raw.drop_channels(['VEOG_lower', 'HEOG_right', 'HEOG_left'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc12620",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Then we load the locations of the EEG electrodes as provided by the manufacturer of the EEG system.\n",
    "Many of these standard EEG montages are shipped with MNE-Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125371b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.set_montage('biosemi64', match_case=False)\n",
    "_ = raw.plot_sensors(show_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea422511",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Filter data\n",
    "\n",
    "Filtering is a common preprocessing step that is used to remove parts of the EEG signal that are unlikely to contain brain activity of interest.\n",
    "There are four different types of filters:\n",
    "\n",
    "* A **high-pass filter** removes low-frequency noise (e.g., slow drifts due to sweat or breathing)\n",
    "* A **low-pass filter** removes high-frequency noise (e.g., muscle activity)\n",
    "* A **band-pass filter** combines a high-pass and a low-pass filter\n",
    "* A **band-stop filter** removes a narrow band of frequencies (e.g., 50 Hz line noise)\n",
    "\n",
    "We first apply a high-pass filter at 0.1 Hz to remove slow drifts and plot the filtered data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996bc3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.filter(l_freq=0.1, h_freq=None)\n",
    "_ = raw.plot(start=60.0, duration=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e994a4a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Next, we apply a low-pass filter at 30 Hz to remove high-frequency noise and plot the data again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.filter(l_freq=None, h_freq=30.0)\n",
    "_ = raw.plot(start=60.0, duration=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ea953",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Note that we've performed these two filters separately for demonstration purposes, but we could have also applied a single band-pass filter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18641e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Correct eye artifacts\n",
    "\n",
    "Eye blinks and eye movements are the most prominent source of artifacts in EEG data.\n",
    "They are approximately 10 times larger than the brain signals we are interested in and affect especially the frontal electrodes.\n",
    "\n",
    "There are multiple ways to remove eye artifacts from EEG data.\n",
    "The most common one is a machine learning technique called **independent component analysis (ICA)**.\n",
    "ICA decomposes the EEG data into a set of independent components, each of which represents a different source of EEG activity.\n",
    "\n",
    "Each component is characterized by a topography (i.e., a spatial pattern of activity across electrodes) and a time course (i.e., a pattern of activity over time).\n",
    "We can then identify those components that we think reflect eye artifacts, and remove them from the data.\n",
    "\n",
    "ICA is typically computed based on a high-pass filtered copy of the data (cutoff = 1 Hz).\n",
    "We ask the algorithm to identify 15 components and plot their scalp topographies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ac661",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_copy = raw.copy().filter(l_freq=1.0, h_freq=None)\n",
    "ica = ICA(n_components=15)\n",
    "ica = ica.fit(raw_copy)\n",
    "_ = ica.plot_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669536ed",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Then we can use a clever method that automatically identifies components that a likely to reflect eye artifacts (based on the correlation of the component's time course with our two VEOG and HEOG channels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd22d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "eog_indices, eog_scores = ica.find_bads_eog(raw, ch_name=['HEOG', 'VEOG'],\n",
    "                                            verbose=False)\n",
    "ica.exclude = eog_indices\n",
    "_ = ica.plot_scores(eog_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26dbcec",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Finally, by \"applying\" the ICA to the data (formally, back-projecting the non-artifact components from component space to channel space), we can remove the eye artifacts from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = ica.apply(raw)\n",
    "_ = raw.plot(start=60.0, duration=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb8092",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Re-reference data\n",
    "\n",
    "**Re-referencing** is our final preprocessing step.\n",
    "Since the EEG signal is measured as the difference in voltage between two electrodes, the signal at any given electrode depends strongly on the \"online\" reference electrode (typically placed on the mastoid bone behind the ear or on the forehead).\n",
    "\n",
    "During preprocessing (\"offline\"), we typically want to re-reference the data to a more neutral (and less noisy) reference, such as the average of all channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fae9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.set_eeg_reference('average')\n",
    "_ = raw.plot(start=60.0, duration=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e7214",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Re-run the above analysis for a different experiment.\n",
    "   For this, you can simply reuse the code cells above, changing only the second cell.\n",
    "   Valid experiment names are `'N170'`, `'MMN'`, `'N2pc'`, `'N400'`, `'P3'`, or `'ERN'`.\n",
    "2. Below, try out the effect of different filter settings such as a higher high-pass cutoff or a lower low-pass cutoff.\n",
    "   For this, write your own code that achieves the following:\n",
    "   (a) read the raw data from one participant,\n",
    "   (b) apply your own custom high-pass, low-pass, or band-pass filter,\n",
    "   (c) plot the filtered data, and\n",
    "   (d) repeat for different filter settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa59fd",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cccfc1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Further reading\n",
    "\n",
    "* Tutorials on preprocessing on the [MNE-Python website](https://mne.tools/stable/auto_tutorials/preprocessing/index.html)\n",
    "* Blog post on [*Pitfalls of filtering the EEG signal*](https://sapienlabs.org/lab-talk/pitfalls-of-filtering-the-eeg-signal/) by Narayan P. Subramaniyam\n",
    "* Paper *EEG is better left alone* {cite:p}`delorme2023`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de57302",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
