{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5c4897",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Epoching\n",
    "\n",
    "We are typically not interested in the full continuous EEG recording, but only in the EEG activity that happens around certain **events** of interest.\n",
    "Such events could be the onset of a stimulus or the onset of a response.\n",
    "\n",
    "The events are usually stored in the EEG data as \"triggers\" (also called \"markers\" or \"annotations\").\n",
    "These are numerical codes at certain timepoints that indicate the onset of an event.\n",
    "We can use them to \"cut\" the continuous EEG recording into smaller segments (called **epochs**) that begin a few hundred milliseconds before the event (to have a neutral \"baseline\" period) and end a few hundred milliseconds after the event (to capture brain activity related to the event).\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"https://files.mtstatic.com/site_7339/94057/0?Expires=1700853581&Signature=UeBaEMEJOBCxd9GX-iXbaSsW6XPM4iX2uABmaWUjOB1~qIaRQf-m4158~2wbQeVqmaaLPnX6o04fkunrzmP88Gr-zGgPhrMBes0MEkLXLy7B43XgdPwUPpO3tUVhOjvHrAuQthoD9lv9b2IYJNsFZ1hcLWeW4ZsezFs7~iSTMFM_&Key-Pair-Id=APKAJ5Y6AV4GI7A555NA\" alt=\"Continuous, epoched, and averaged EEG\" width=500>\n",
    "\n",
    "Continuous, epoched, and averaged EEG.\n",
    "Source: {cite:t}`luck2022a`\n",
    ":::\n",
    "\n",
    "```{admonition} Goals\n",
    ":class: note\n",
    "\n",
    "* Extracting event information from the data\n",
    "* Segmenting the data into epochs\n",
    "* Applying baseline correction\n",
    "* Rejecting high-amplitude epochs\n",
    "* Visualizing the epoched data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea14e2c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Load Python modules\n",
    "\n",
    "As before, we'll make extensive use of the [MNE-Python](https://mne.tools/stable/index.html) package{cite:p}`gramfort2013`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install mne hu-neuro-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mne import (Epochs, events_from_annotations, merge_events,\n",
    "                 set_bipolar_reference)\n",
    "from mne.io import read_raw\n",
    "from mne.preprocessing import ICA\n",
    "from pipeline.datasets import get_erpcore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b810fc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Recreate preprocessing\n",
    "\n",
    "We repeat the preprocessing steps from the previous chapter in condensed form (without any intermediate plots).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9df27",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "files_dict = get_erpcore('N170', participants='sub-004', path='data')\n",
    "raw_file = files_dict['raw_files'][0]\n",
    "log_file = files_dict['log_files'][0]\n",
    "\n",
    "# Preprocessing\n",
    "raw = read_raw(raw_file, preload=True)\n",
    "raw = set_bipolar_reference(raw, anode='FP1', cathode='VEOG_lower',\n",
    "                            ch_name='VEOG', drop_refs=False)\n",
    "raw = set_bipolar_reference(raw, anode='HEOG_right', cathode='HEOG_left',\n",
    "                            ch_name='HEOG', drop_refs=False)\n",
    "raw = raw.set_channel_types({'VEOG': 'eog', 'HEOG': 'eog'})\n",
    "raw = raw.drop_channels(['VEOG_lower', 'HEOG_right', 'HEOG_left'])\n",
    "raw = raw.set_montage('biosemi64', match_case=False)\n",
    "raw = raw.filter(l_freq=0.1, h_freq=30.0)\n",
    "raw_copy = raw.copy().filter(l_freq=1.0, h_freq=None, verbose=False)\n",
    "ica = ICA(n_components=15)\n",
    "ica = ica.fit(raw_copy)\n",
    "eog_indices, eog_scores = ica.find_bads_eog(raw, ch_name=['VEOG', 'HEOG'],\n",
    "                                            verbose=False)\n",
    "ica.exclude = eog_indices\n",
    "raw = ica.apply(raw)\n",
    "raw = raw.set_eeg_reference('average')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16118f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This gives us the cleaned, continuous EEG data as a `Raw` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15910a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2858d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Extract events\n",
    "\n",
    "We can extract the event codes that are stored within the raw data using the `events_from_annotations()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e085f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, event_id = events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6a11d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This functions returns two outputs:\n",
    "\n",
    "* `events` is a Numpy array with three columns: the sample number (timepoint) of each event, the duration of the event, and the event code (here indicating the specific face or car stimulus)\n",
    "* `event_id`: a dictionary mapping the event codes to human-readable names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923399d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2caefb",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b1e26",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "An alternative way to get the events is to use an explicit events file that accompanies the raw data.\n",
    "This is useful if there are no events stored in the raw data or if they are erroneous (as is actually the case here for the N170 dataset!).\n",
    "\n",
    "For instance, the EEG data from each participant in the ERP CORE datasets (e.g., `sub-004_task-N170_eeg.set`) is accompanied by a tab-separated events file (e.g., `sub-004_task-N170_events.tsv`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b7467",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "%cat data/erpcore/N170/sub-004/eeg/sub-004_task-N170_events.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86100e63",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We can read this file using the pandas package, which offers a `DataFrame` type for working tabular data (similar to a `data.frame` or `tibble` in R).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = files_dict['log_files'][0]\n",
    "log = pd.read_csv(log_file, sep='\\t')\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c4c7f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "From this data frame, we can re-create the 3-column `events` array (see above), now with the correct timings and event codes.\n",
    "Note that by converting all columns from floats to integers, we are rounding the duration of the events from `0.3` (the actual length of the stimulus) to `0`, as is common practice in ERP analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b69501",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = log[['sample', 'duration', 'value']].values.astype(int)\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2ecd0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "However, these many different numerical event codes still have no obvious meaning to us.\n",
    "We can check what they stand for by looking at the `task-N170_events.json` file that accompanies the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat data/erpcore/N170/task-N170_events.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed08266",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We see that triggers 1--40 correspond to face stimuli, and triggers 41--80 correspond to car stimuli.\n",
    "To make our epoching job easier, we'll collapse these 80 original event codes into just two event codes: `1` for faces and `2` for cars, using MNE's `merge_events()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = merge_events(events, ids=range(1, 41), new_id=1)\n",
    "events = merge_events(events, ids=range(41, 81), new_id=2)\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f3806",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Note that `range()` is a built-in Python function that generates a sequence of numbers (integers) between a start and end value.\n",
    "For example, `range(1, 41)` generates the sequence 1, 2, ..., 40 (the end value is not included).\n",
    "\n",
    "We also need to update the `event_id` dictionary accordingly, mapping the new event codes to human-readable condition labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ab24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = {'face': 1, 'car': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf4728",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Epoching\n",
    "\n",
    "No we're ready to segment our raw data into epochs, using the `events` and `event_id` that we just created.\n",
    "We'll use a time window of 1 s, starting 200 ms before the event onset.\n",
    "\n",
    "For now, we'll skip baseline correction (this would be enabled by default) because we want to show the effect of baseline correction later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = Epochs(raw, events, event_id, tmin=-0.2, tmax=0.8, baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b45870",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc2e1b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We see that the dimensions have changed, from EEG channels × timepoints (`raw`) to epochs × EEG channels × timepoints (`epochs`).\n",
    "\n",
    "Just as the raw data, the epochs also have a `plot()` method to visualize the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = epochs.plot(events=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d0d78",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Another effective way of visualizing *all* epochs in the dataset is the so-called **ERP image** plot.\n",
    "This is a heatmap with time on the x-axis, epochs on the y-axis, and the EEG amplitude represented by color.\n",
    "\n",
    "We'll create this plot for a single EEG channel (`'PO8'`) that is typically sensitive to the N170 face effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbf733",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = epochs.plot_image(picks='PO8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa5236",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This type of plot could also be used to check for interesting patterns in the data, e.g., by sorting the epochs on the y-axis by some variables of interest (e.g., stimulus condition or reaction time).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a427d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Baseline correction\n",
    "\n",
    "Some of the epochs have a large offset (vertical shift) compared to the other epochs, which can happen due to technical or physiological drifts at some channels.\n",
    "\n",
    "We can remove these offsets by applying a baseline correction.\n",
    "This works by, separately for each channel, subtracting the mean of the baseline activity from each timepoint in the epoch.\n",
    "The baseline activity is typically defined as the 200 ms prior to the event onset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs.apply_baseline((-0.2, 0.0))\n",
    "_ = epochs.plot(events=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94316eb4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Rejecting bad epochs\n",
    "\n",
    "Despite all our data cleaning efforts (filtering, ICA, referencing, baseline correction), some epochs will still contain large-amplitude artifacts, e.g., due to movements or technical glitches.\n",
    "\n",
    "We can \"reject\" (delete) these epochs from the data by using the `drop_bad()` method (or, alternatively, the `reject=...` argument of the `Epochs` constructor).\n",
    "This allows us to specify a peak-to-peak-threshold (in volts).\n",
    "If, at any channel, the difference between the minimum and maximum amplitude in an epoch exceeds this threshold, the epoch will be rejected (deleted).\n",
    "\n",
    "Depending on how clean the dataset is, this threshold will typically be between 50 and 200 µV.\n",
    "Note that the lower the threshold (that is, the more epochs we're rejecting), the cleaner the remaining epochs will be, but the fewer epochs we'll have left, potentially reducing our statistical power.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af382883",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs.drop_bad({'eeg': 100e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29861d7c",
   "metadata": {},
   "source": [
    "We see that the ERP image now has a reduced number of epochs (rows), but the color patterns are much clearer (as some large-amplitude epochs have been removed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = epochs.plot_image(picks='PO8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894048f7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Repeat the preprocessing (first code cell) for a different ERP CORE experiment (valid experiment names are `'N170'`, `'MMN'`, `'N2pc'`, `'N400'`, `'P3'`, or `'ERN'`).\n",
    "   Then check the `task-<experiment>_events.json` file and construct the correct `events` and `event_id` variables.\n",
    "   Finally, create epochs from the data and plot the ERP image for a channel that is typically sensitive to the effect of interest (check {cite:t}`kappenman2021`, Table 1, for a suggestion).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5864cc20",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "%cat data/erpcore/.../task-..._events.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e22c91",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270bdf9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Further reading\n",
    "\n",
    "* Online chapter [*Segmentation into ERP epochs*](https://neuraldatascience.io/7-eeg/erp_segmentation.html) in {cite:t}`newman2020`\n",
    "* Tutorial on epochs on the [MNE-Python website](https://mne.tools/stable/auto_tutorials/epochs/10_epochs_overview.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd628bf5",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
